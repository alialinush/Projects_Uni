{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33bae8e-712d-4fec-adbe-31228aaa3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomContrast, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import datetime\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f7369ac-8b90-4cd7-898a-352a89b966df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "epoch = 30\n",
    "batch_size = 32\n",
    "target_size = (299, 299)\n",
    "\n",
    "def load_and_preprocess_images(data_df, image_folder, target_size):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for index, row in data_df.iterrows():\n",
    "        img_filename = row['image_path'][1:]  # Remove leading \"/\"\n",
    "        img_path = os.path.join(image_folder, img_filename)\n",
    "        label = row['label'] - 1\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        img = img / 255.0\n",
    "\n",
    "        X.append(img)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa84e189-6ff5-49ac-8540-7e657a2ac277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train_df = pd.read_csv(\"train_images.csv\")\n",
    "script_dir = os.getcwd()\n",
    "train_images = os.path.join(script_dir, 'train_images')\n",
    "\n",
    "X_train, y_train = load_and_preprocess_images(train_df, train_images, target_size)\n",
    "\n",
    "# Shuffle the data\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 215s 2s/step - loss: 4.1947 - accuracy: 0.1901 - val_loss: 3.1654 - val_accuracy: 0.3448\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 209s 2s/step - loss: 2.4937 - accuracy: 0.4863 - val_loss: 2.4622 - val_accuracy: 0.4453\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 206s 2s/step - loss: 1.8535 - accuracy: 0.6303 - val_loss: 2.1411 - val_accuracy: 0.4962\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 202s 2s/step - loss: 1.4896 - accuracy: 0.7188 - val_loss: 1.9526 - val_accuracy: 0.5165\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 200s 2s/step - loss: 1.2451 - accuracy: 0.7627 - val_loss: 1.8038 - val_accuracy: 0.5445\n",
      "Validation accuracy: 0.3447837233543396\n",
      "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 216s 2s/step - loss: 3.5683 - accuracy: 0.3146 - val_loss: 2.7008 - val_accuracy: 0.4288\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 203s 2s/step - loss: 1.3943 - accuracy: 0.6242 - val_loss: 2.1681 - val_accuracy: 0.5229\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 194s 2s/step - loss: 0.8540 - accuracy: 0.7538 - val_loss: 2.0978 - val_accuracy: 0.5204\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 197s 2s/step - loss: 0.5688 - accuracy: 0.8217 - val_loss: 2.2054 - val_accuracy: 0.5102\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 194s 2s/step - loss: 0.4047 - accuracy: 0.8841 - val_loss: 1.9749 - val_accuracy: 0.5407\n",
      "Validation accuracy: 0.42875316739082336\n",
      "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 210s 2s/step - loss: 26.1994 - accuracy: 0.2210 - val_loss: 17.4326 - val_accuracy: 0.3270\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 201s 2s/step - loss: 11.5061 - accuracy: 0.4704 - val_loss: 18.8711 - val_accuracy: 0.3791\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 200s 2s/step - loss: 9.1480 - accuracy: 0.5882 - val_loss: 14.9112 - val_accuracy: 0.4555\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 201s 2s/step - loss: 7.1160 - accuracy: 0.6525 - val_loss: 17.0466 - val_accuracy: 0.4211\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 198s 2s/step - loss: 5.4637 - accuracy: 0.7175 - val_loss: 17.6666 - val_accuracy: 0.4593\n",
      "Validation accuracy: 0.32697200775146484\n",
      "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 212s 2s/step - loss: 4.2983 - accuracy: 0.1694 - val_loss: 3.2648 - val_accuracy: 0.3410\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 200s 2s/step - loss: 2.6405 - accuracy: 0.4567 - val_loss: 2.5245 - val_accuracy: 0.4402\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 211s 2s/step - loss: 2.0089 - accuracy: 0.5717 - val_loss: 2.2165 - val_accuracy: 0.4720\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 202s 2s/step - loss: 1.6368 - accuracy: 0.6643 - val_loss: 2.0062 - val_accuracy: 0.5115\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 201s 2s/step - loss: 1.3860 - accuracy: 0.7213 - val_loss: 1.8783 - val_accuracy: 0.5318\n",
      "Validation accuracy: 0.3409669101238251\n",
      "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 217s 2s/step - loss: 3.6337 - accuracy: 0.2752 - val_loss: 2.2881 - val_accuracy: 0.4542\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 199s 2s/step - loss: 1.5304 - accuracy: 0.5924 - val_loss: 2.1949 - val_accuracy: 0.4733\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 199s 2s/step - loss: 1.1572 - accuracy: 0.6815 - val_loss: 2.0457 - val_accuracy: 0.5420\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 199s 2s/step - loss: 0.8243 - accuracy: 0.7627 - val_loss: 2.2670 - val_accuracy: 0.4936\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 195s 2s/step - loss: 0.6452 - accuracy: 0.8051 - val_loss: 2.1504 - val_accuracy: 0.5369\n",
      "Validation accuracy: 0.4541984796524048\n",
      "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 212s 2s/step - loss: 23.4781 - accuracy: 0.2054 - val_loss: 16.5283 - val_accuracy: 0.3295\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 203s 2s/step - loss: 12.5848 - accuracy: 0.4366 - val_loss: 16.1419 - val_accuracy: 0.3804\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 200s 2s/step - loss: 11.0730 - accuracy: 0.5166 - val_loss: 16.6724 - val_accuracy: 0.4198\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 198s 2s/step - loss: 9.0377 - accuracy: 0.5863 - val_loss: 16.9006 - val_accuracy: 0.4466\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 195s 2s/step - loss: 7.7806 - accuracy: 0.6395 - val_loss: 18.5272 - val_accuracy: 0.4529\n",
      "Validation accuracy: 0.32951653003692627\n",
      "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 214s 2s/step - loss: 4.5374 - accuracy: 0.1143 - val_loss: 3.5031 - val_accuracy: 0.3130\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 203s 2s/step - loss: 2.9443 - accuracy: 0.3831 - val_loss: 2.7205 - val_accuracy: 0.3931\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 207s 2s/step - loss: 2.2925 - accuracy: 0.4978 - val_loss: 2.3632 - val_accuracy: 0.4402\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 203s 2s/step - loss: 1.9245 - accuracy: 0.5646 - val_loss: 2.1412 - val_accuracy: 0.4898\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 199s 2s/step - loss: 1.6627 - accuracy: 0.6354 - val_loss: 1.9979 - val_accuracy: 0.5153\n",
      "Validation accuracy: 0.3129771053791046\n",
      "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 213s 2s/step - loss: 4.1419 - accuracy: 0.2172 - val_loss: 2.4383 - val_accuracy: 0.4008\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 201s 2s/step - loss: 2.4438 - accuracy: 0.4395 - val_loss: 2.3647 - val_accuracy: 0.4618\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 199s 2s/step - loss: 2.0495 - accuracy: 0.5261 - val_loss: 2.1684 - val_accuracy: 0.5051\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 200s 2s/step - loss: 1.7080 - accuracy: 0.5873 - val_loss: 2.3114 - val_accuracy: 0.4771\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 200s 2s/step - loss: 1.5825 - accuracy: 0.6210 - val_loss: 2.2415 - val_accuracy: 0.5331\n",
      "Validation accuracy: 0.4007633626461029\n",
      "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "99/99 [==============================] - 213s 2s/step - loss: 19.4139 - accuracy: 0.1545 - val_loss: 15.9813 - val_accuracy: 0.3193\n",
      "Epoch 2/5\n",
      "99/99 [==============================] - 204s 2s/step - loss: 17.8582 - accuracy: 0.3315 - val_loss: 15.8487 - val_accuracy: 0.3766\n",
      "Epoch 3/5\n",
      "99/99 [==============================] - 197s 2s/step - loss: 16.5330 - accuracy: 0.4194 - val_loss: 14.8505 - val_accuracy: 0.4631\n",
      "Epoch 4/5\n",
      "99/99 [==============================] - 198s 2s/step - loss: 14.5345 - accuracy: 0.4777 - val_loss: 15.2455 - val_accuracy: 0.4567\n",
      "Epoch 5/5\n",
      "99/99 [==============================] - 198s 2s/step - loss: 14.4868 - accuracy: 0.5096 - val_loss: 18.1248 - val_accuracy: 0.4288\n",
      "Validation accuracy: 0.3193384110927582\n",
      "Best validation accuracy: 0.4541984796524048\n",
      "Best hyperparameters: {'dropout_rate': 0.5, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def create_model(learning_rate, dropout_rate):\n",
    "    base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    dropout = Dropout(dropout_rate)(avg)\n",
    "    output = tf.keras.layers.Dense(200, activation=\"softmax\")(dropout)\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Define a grid of hyperparameters to search through\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7]\n",
    "}\n",
    "\n",
    "best_val_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Iterate through each combination of hyperparameters\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Training with params: {params}\")\n",
    "    \n",
    "    # Create and compile the model with current hyperparameters\n",
    "    model = create_model(params['learning_rate'], params['dropout_rate'])\n",
    "    \n",
    "    # Train the model for one epoch\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=5,\n",
    "        validation_data=(X_val, y_val)  # Set verbose to 0 to avoid printing training progress\n",
    "    )\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_accuracy = history.history['val_accuracy'][0]\n",
    "    print(f\"Validation accuracy: {val_accuracy}\")\n",
    " \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best validation accuracy: {best_val_accuracy}\")\n",
    "print(f\"Best hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers\n",
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "dropout = Dropout(0.3)(avg) \n",
    "output = tf.keras.layers.Dense(200, activation=\"softmax\")(dropout)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "99/99 [==============================] - 213s 2s/step - loss: 4.1784 - accuracy: 0.1924 - val_loss: 3.1652 - val_accuracy: 0.3193\n",
      "Epoch 2/30\n",
      "99/99 [==============================] - 204s 2s/step - loss: 2.5016 - accuracy: 0.4838 - val_loss: 2.4705 - val_accuracy: 0.4338\n",
      "Epoch 3/30\n",
      "99/99 [==============================] - 202s 2s/step - loss: 1.8580 - accuracy: 0.6242 - val_loss: 2.1302 - val_accuracy: 0.4847\n",
      "Epoch 4/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 1.4834 - accuracy: 0.7108 - val_loss: 1.9386 - val_accuracy: 0.5305\n",
      "Epoch 5/30\n",
      "99/99 [==============================] - 199s 2s/step - loss: 1.2434 - accuracy: 0.7650 - val_loss: 1.8184 - val_accuracy: 0.5382\n",
      "Epoch 6/30\n",
      "99/99 [==============================] - 200s 2s/step - loss: 1.0642 - accuracy: 0.8080 - val_loss: 1.7202 - val_accuracy: 0.5623\n",
      "Epoch 7/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.9349 - accuracy: 0.8303 - val_loss: 1.6465 - val_accuracy: 0.5852\n",
      "Epoch 8/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.8274 - accuracy: 0.8615 - val_loss: 1.6215 - val_accuracy: 0.5662\n",
      "Epoch 9/30\n",
      "99/99 [==============================] - 199s 2s/step - loss: 0.7420 - accuracy: 0.8793 - val_loss: 1.5946 - val_accuracy: 0.5687\n",
      "Epoch 10/30\n",
      "99/99 [==============================] - 209s 2s/step - loss: 0.6588 - accuracy: 0.8981 - val_loss: 1.5639 - val_accuracy: 0.5751\n",
      "Epoch 11/30\n",
      "99/99 [==============================] - 203s 2s/step - loss: 0.6009 - accuracy: 0.9166 - val_loss: 1.5256 - val_accuracy: 0.5891\n",
      "Epoch 12/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.5494 - accuracy: 0.9207 - val_loss: 1.5239 - val_accuracy: 0.5852\n",
      "Epoch 13/30\n",
      "99/99 [==============================] - 203s 2s/step - loss: 0.5018 - accuracy: 0.9360 - val_loss: 1.5288 - val_accuracy: 0.5814\n",
      "Epoch 14/30\n",
      "99/99 [==============================] - 202s 2s/step - loss: 0.4508 - accuracy: 0.9449 - val_loss: 1.4877 - val_accuracy: 0.5827\n",
      "Epoch 15/30\n",
      "99/99 [==============================] - 199s 2s/step - loss: 0.4228 - accuracy: 0.9471 - val_loss: 1.4871 - val_accuracy: 0.5929\n",
      "Epoch 16/30\n",
      "99/99 [==============================] - 199s 2s/step - loss: 0.3956 - accuracy: 0.9475 - val_loss: 1.4831 - val_accuracy: 0.5903\n",
      "Epoch 17/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.3605 - accuracy: 0.9643 - val_loss: 1.4789 - val_accuracy: 0.5980\n",
      "Epoch 18/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.3350 - accuracy: 0.9624 - val_loss: 1.4739 - val_accuracy: 0.5992\n",
      "Epoch 19/30\n",
      "99/99 [==============================] - 204s 2s/step - loss: 0.3131 - accuracy: 0.9685 - val_loss: 1.4696 - val_accuracy: 0.5967\n",
      "Epoch 20/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.2896 - accuracy: 0.9758 - val_loss: 1.4618 - val_accuracy: 0.6018\n",
      "Epoch 21/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.2714 - accuracy: 0.9774 - val_loss: 1.4756 - val_accuracy: 0.5891\n",
      "Epoch 22/30\n",
      "99/99 [==============================] - 200s 2s/step - loss: 0.2546 - accuracy: 0.9777 - val_loss: 1.4639 - val_accuracy: 0.5891\n",
      "Epoch 23/30\n",
      "99/99 [==============================] - 202s 2s/step - loss: 0.2367 - accuracy: 0.9847 - val_loss: 1.4583 - val_accuracy: 0.6018\n",
      "Epoch 24/30\n",
      "99/99 [==============================] - 201s 2s/step - loss: 0.2276 - accuracy: 0.9828 - val_loss: 1.4673 - val_accuracy: 0.5992\n",
      "Epoch 25/30\n",
      "99/99 [==============================] - 198s 2s/step - loss: 0.2147 - accuracy: 0.9873 - val_loss: 1.4689 - val_accuracy: 0.6005\n",
      "Epoch 26/30\n",
      "99/99 [==============================] - 199s 2s/step - loss: 0.1983 - accuracy: 0.9854 - val_loss: 1.4642 - val_accuracy: 0.5941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x299b97b10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=epoch,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data paths\n",
    "test_df = pd.read_csv(\"test_images_path.csv\")\n",
    "test_images = os.path.join(script_dir, 'test_images')\n",
    "X_test, _ = load_and_preprocess_images(test_df, test_images, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 213s 2s/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1) + 1\n",
    "\n",
    "# Update the 'label' column in the test dataframe with the predicted labels\n",
    "test_df['label'] = predicted_labels\n",
    "\n",
    "selected_columns = ['id', 'label']\n",
    "test_df_selected = test_df[selected_columns]\n",
    "\n",
    "# Generate a timestamp for the filename\n",
    "current_datetime = datetime.datetime.now()\n",
    "timestamp = current_datetime.strftime(\"%Y%m%d_%H%M\")\n",
    "file_name = f\"submission_{timestamp}.csv\"\n",
    "\n",
    "# Define the folder for submissions\n",
    "submissions_folder = os.path.join(script_dir, 'submissions')\n",
    "\n",
    "# Specify the full file path\n",
    "file_path = os.path.join(submissions_folder, file_name)\n",
    "\n",
    "# Save the final submission file\n",
    "test_df_selected.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
