{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U7RP2F6DAnqf",
        "outputId": "58b43622-2258-43b5-a1f3-e6a97ed06e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.12-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-macosx_11_0_arm64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (10.0.1)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.17.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (1.26.18)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from matplotlib->roboflow) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from matplotlib->roboflow) (4.25.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from requests->roboflow) (2.0.4)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /Users/jaimeponsgarrido/miniconda3/lib/python3.11/site-packages (from supervision->roboflow) (1.11.4)\n",
            "Downloading roboflow-1.1.12-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading supervision-0.17.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.11.17\n",
            "    Uninstalling certifi-2023.11.17:\n",
            "      Successfully uninstalled certifi-2023.11.17\n",
            "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.12 supervision-0.17.1\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in aml_train-1 to folder:: 100%|██████████| 105020/105020 [00:10<00:00, 10301.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to aml_train-1 in folder:: 100%|██████████| 4129/4129 [00:00<00:00, 6312.22it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Insert your API key\")\n",
        "project = rf.workspace(\"uni-4phrc\").project(\"aml_train\")\n",
        "dataset = project.version(1).download(\"folder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmLcfm8CaPJJ",
        "outputId": "2df977ce-ee3b-493c-b938-d9cd4e1ae0de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in aml_test-1 to folder:: 100%|██████████| 107608/107608 [00:10<00:00, 10488.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to aml_test-1 in folder:: 100%|██████████| 4004/4004 [00:00<00:00, 7084.70it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=\"Insert your API key\")\n",
        "project = rf.workspace(\"uni-4phrc\").project(\"aml_test\")\n",
        "dataset = project.version(1).download(\"folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in BirdDeep-1 to folder:: 100%|██████████| 349899/349899 [00:34<00:00, 10187.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to BirdDeep-1 in folder:: 100%|██████████| 23294/23294 [00:03<00:00, 6577.87it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=\"Insert your API key\")\n",
        "project = rf.workspace(\"aml-cg1zr\").project(\"birddeep-bla72\")\n",
        "dataset = project.version(1).download(\"folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Exporting format folder in progress : 85.0%\n",
            "Version export complete for folder format\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in BirdDeep-2 to folder:: 100%|██████████| 686369/686369 [01:04<00:00, 10623.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to BirdDeep-2 in folder:: 100%|██████████| 23294/23294 [00:03<00:00, 6503.52it/s]\n"
          ]
        }
      ],
      "source": [
        "rf = Roboflow(api_key=\"Insert your API key\")\n",
        "project = rf.workspace(\"aml-cg1zr\").project(\"birddeep-bla72\")\n",
        "dataset = project.version(2).download(\"folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_mx9G2muB1MB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.layers import RandomFlip, RandomRotation, RandomContrast, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import datetime\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dyfxZuYCCyo-"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"train_images.csv\")\n",
        "test_df = pd.read_csv(\"test_images_path.csv\")\n",
        "\n",
        "train_folder = './BirdDeep-1/train'\n",
        "test_folder = './aml_test-1/test/test_images'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5YkI1veFF9V",
        "outputId": "9b788604-2fd2-4447-acbc-737fdd43be0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14726 files belonging to 200 classes.\n",
            "Using 11781 files for training.\n"
          ]
        }
      ],
      "source": [
        "# Load train data\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_folder,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  labels='inferred',\n",
        "  class_names=train_df['label'].apply(lambda x: str(x)).unique().tolist(),\n",
        "  seed=42,\n",
        "  image_size=(299, 299),\n",
        "  batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD2zwSprCmCB",
        "outputId": "e556a7af-14df-4532-99e2-e28808eebb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14726 files belonging to 200 classes.\n",
            "Using 2945 files for validation.\n"
          ]
        }
      ],
      "source": [
        "# Load validation data\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_folder,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  labels='inferred',\n",
        "  class_names=train_df['label'].apply(lambda x: str(x)).unique().tolist(),\n",
        "  seed=42,\n",
        "  image_size=(299, 299),\n",
        "  batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rl2PGn2BCQzl"
      },
      "outputs": [],
      "source": [
        "# Load test data paths\n",
        "test_df = pd.read_csv(\"test_images_path.csv\")\n",
        "test_images = test_folder = './aml_test-1/test/test_images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r-BUBweFjau",
        "outputId": "76e8bafa-6938-43e0-d473-58309a33cf00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4000 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "# Load test data\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  test_folder,\n",
        "  labels=None,\n",
        "  seed=42,\n",
        "  shuffle = False,\n",
        "  image_size=(299, 299),\n",
        "  batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "CvGShriFRezO"
      },
      "outputs": [],
      "source": [
        "#Normalization\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "test_ds = test_ds.map(lambda x: (normalization_layer(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn5wdYOSFBS6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iw-VDNzzUmd",
        "outputId": "add8494c-de84-4727-9ed5-6a3311a7b47b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "# run below if you want to check normalization\n",
        "image_batch, labels_batch = next(iter(train_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh4MLx55OdjT"
      },
      "source": [
        "\n",
        "**Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:34:14.430035: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-12-14 22:34:14.527199: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 211s 4s/step - loss: 3.3981 - accuracy: 0.2878 - val_loss: 2.2561 - val_accuracy: 0.4716\n",
            "Validation accuracy: 0.47164684534072876\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.001}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:37:46.800532: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 209s 4s/step - loss: 4.5535 - accuracy: 0.1445 - val_loss: 3.7615 - val_accuracy: 0.3188\n",
            "Validation accuracy: 0.3188455104827881\n",
            "Training with params: {'dropout_rate': 0.3, 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:41:18.428217: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 211s 4s/step - loss: 4.8880 - accuracy: 0.0884 - val_loss: 4.4129 - val_accuracy: 0.2486\n",
            "Validation accuracy: 0.24855688214302063\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:44:50.171945: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 213s 4s/step - loss: 3.5259 - accuracy: 0.2551 - val_loss: 2.3577 - val_accuracy: 0.4611\n",
            "Validation accuracy: 0.4611205458641052\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.001}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:48:26.203618: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 216s 5s/step - loss: 4.6471 - accuracy: 0.1205 - val_loss: 3.8830 - val_accuracy: 0.3236\n",
            "Validation accuracy: 0.32359930872917175\n",
            "Training with params: {'dropout_rate': 0.5, 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:52:00.988609: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 213s 4s/step - loss: 4.9796 - accuracy: 0.0573 - val_loss: 4.4967 - val_accuracy: 0.2224\n",
            "Validation accuracy: 0.2224108725786209\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:55:35.226680: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 211s 4s/step - loss: 3.8645 - accuracy: 0.1778 - val_loss: 2.4844 - val_accuracy: 0.4482\n",
            "Validation accuracy: 0.44821733236312866\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.001}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 22:59:10.508554: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 217s 5s/step - loss: 4.7827 - accuracy: 0.0786 - val_loss: 4.0486 - val_accuracy: 0.3022\n",
            "Validation accuracy: 0.3022071421146393\n",
            "Training with params: {'dropout_rate': 0.7, 'learning_rate': 0.0005}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
            "2023-12-14 23:02:46.122777: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 212s 4s/step - loss: 5.0727 - accuracy: 0.0354 - val_loss: 4.5889 - val_accuracy: 0.2105\n",
            "Validation accuracy: 0.21052631735801697\n",
            "Best validation accuracy: 0.47164684534072876\n",
            "Best hyperparameters: {'dropout_rate': 0.3, 'learning_rate': 0.005}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "# Define a function to create and compile the model with given hyperparameters\n",
        "def create_model(learning_rate, dropout_rate):\n",
        "    base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
        "    avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    dropout = Dropout(dropout_rate)(avg)\n",
        "    output = tf.keras.layers.Dense(200, activation=\"softmax\")(dropout)\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define a grid of hyperparameters to search through\n",
        "param_grid = {\n",
        "    'learning_rate': [0.005, 0.001, 0.0005],\n",
        "    'dropout_rate': [0.3, 0.5, 0.7]\n",
        "}\n",
        "\n",
        "best_val_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "# Iterate through each combination of hyperparameters\n",
        "for params in ParameterGrid(param_grid):\n",
        "    print(f\"Training with params: {params}\")\n",
        "    \n",
        "    # Create and compile the model with current hyperparameters\n",
        "    model = create_model(params['learning_rate'], params['dropout_rate'])\n",
        "    \n",
        "    # Train the model for one epoch\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=1,\n",
        "        validation_data=val_ds  # Set verbose to 0 to avoid printing training progress\n",
        "    )\n",
        "    \n",
        "    # Evaluate the model on the validation set\n",
        "    val_accuracy = history.history['val_accuracy'][0]\n",
        "    print(f\"Validation accuracy: {val_accuracy}\")\n",
        "    \n",
        "    # Check if this set of hyperparameters is the best so far\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_params = params\n",
        "\n",
        "print(f\"Best validation accuracy: {best_val_accuracy}\")\n",
        "print(f\"Best hyperparameters: {best_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU9gosoKmJZG"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CYwX3ML0JfMa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras import regularizers\n",
        "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
        "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "dropout = Dropout(0.3)(avg) \n",
        "output = tf.keras.layers.Dense(200, activation=\"softmax\")(dropout)\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "#output = tf.keras.layers.Dense(200, activation=\"softmax\")(dropout)\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# Implement early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KEcSYwZODwO",
        "outputId": "ba81f3bb-bdfa-473d-8c60-96c707f850f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-14 23:49:10.517479: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "737/737 [==============================] - 187s 248ms/step - loss: 3.2477 - accuracy: 0.3065 - val_loss: 2.2317 - val_accuracy: 0.4944\n",
            "Epoch 2/10\n",
            "737/737 [==============================] - 183s 249ms/step - loss: 1.7546 - accuracy: 0.5923 - val_loss: 1.7796 - val_accuracy: 0.5752\n",
            "Epoch 3/10\n",
            "737/737 [==============================] - 182s 247ms/step - loss: 1.2943 - accuracy: 0.7023 - val_loss: 1.5654 - val_accuracy: 0.6214\n",
            "Epoch 4/10\n",
            "737/737 [==============================] - 183s 248ms/step - loss: 1.0181 - accuracy: 0.7701 - val_loss: 1.4569 - val_accuracy: 0.6387\n",
            "Epoch 5/10\n",
            "737/737 [==============================] - 183s 248ms/step - loss: 0.8330 - accuracy: 0.8147 - val_loss: 1.3698 - val_accuracy: 0.6570\n",
            "Epoch 6/10\n",
            "737/737 [==============================] - 182s 247ms/step - loss: 0.6956 - accuracy: 0.8500 - val_loss: 1.2944 - val_accuracy: 0.6788\n",
            "Epoch 7/10\n",
            "737/737 [==============================] - 183s 249ms/step - loss: 0.5860 - accuracy: 0.8784 - val_loss: 1.2539 - val_accuracy: 0.6829\n",
            "Epoch 8/10\n",
            "737/737 [==============================] - 183s 249ms/step - loss: 0.5006 - accuracy: 0.9008 - val_loss: 1.2236 - val_accuracy: 0.6944\n",
            "Epoch 9/10\n",
            "737/737 [==============================] - 184s 249ms/step - loss: 0.4315 - accuracy: 0.9179 - val_loss: 1.1904 - val_accuracy: 0.7005\n",
            "Epoch 10/10\n",
            "737/737 [==============================] - 184s 250ms/step - loss: 0.3701 - accuracy: 0.9357 - val_loss: 1.1716 - val_accuracy: 0.7063\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x47c61b250>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model with early stopping\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=10,\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yeWH83t7BOgw"
      },
      "outputs": [],
      "source": [
        "def extract_first_number_underscore(string_list):\n",
        "    pattern = r'(\\d+)_\\w+'  # Capture the first sequence of digits before the first underscore\n",
        "    numbers = [re.search(pattern, s).group(1) for s in string_list if re.search(pattern, s)]\n",
        "    return numbers\n",
        "\n",
        "def extract_first_number_points(string_list):\n",
        "    pattern = r'(\\d+).\\w+'  # Capture the first sequence of digits before the first underscore\n",
        "    numbers = [re.search(pattern, s).group(1) for s in string_list if re.search(pattern, s)]\n",
        "    return numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "sFYrrbr6bJLz",
        "outputId": "fcb0799d-8c8e-49d8-f4e1-f2eeb02a1d9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>image_path</th>\n",
              "      <th>label</th>\n",
              "      <th>path_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>3997</td>\n",
              "      <td>/test_images/1000.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>3996</td>\n",
              "      <td>/test_images/1001.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3994</th>\n",
              "      <td>3995</td>\n",
              "      <td>/test_images/1002.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3993</th>\n",
              "      <td>3994</td>\n",
              "      <td>/test_images/1003.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3992</th>\n",
              "      <td>3993</td>\n",
              "      <td>/test_images/1004.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>1004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>/test_images/997.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>/test_images/998.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>/test_images/999.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>/test_images/99.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>111</td>\n",
              "      <td>/test_images/9.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id             image_path  label path_number\n",
              "3996  3997  /test_images/1000.jpg      1        1000\n",
              "3995  3996  /test_images/1001.jpg      1        1001\n",
              "3994  3995  /test_images/1002.jpg      1        1002\n",
              "3993  3994  /test_images/1003.jpg      1        1003\n",
              "3992  3993  /test_images/1004.jpg      1        1004\n",
              "...    ...                    ...    ...         ...\n",
              "2        3   /test_images/997.jpg      1         997\n",
              "1        2   /test_images/998.jpg      1         998\n",
              "0        1   /test_images/999.jpg      1         999\n",
              "10      11    /test_images/99.jpg      1          99\n",
              "110    111     /test_images/9.jpg      1           9\n",
              "\n",
              "[4000 rows x 4 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir_folder = sorted(os.listdir(test_folder))\n",
        "dir_folder_numbers = extract_first_number_underscore(dir_folder)\n",
        "test_path_numbers = extract_first_number_points(test_df.image_path.values.tolist())\n",
        "test_df['path_number'] = test_path_numbers\n",
        "# Convert the 'Values' column to Categorical with custom ordering\n",
        "test_df['path_number'] = pd.Categorical(test_df['path_number'], categories=dir_folder_numbers, ordered=True)\n",
        "\n",
        "# Sort the DataFrame based on the 'Values' column\n",
        "test_df = test_df.sort_values(by='path_number')\n",
        "\n",
        "# Reset the index if needed\n",
        "# test = df_sorted.reset_index(drop=True)\n",
        "\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU6sZ-ypORnF",
        "outputId": "a5d933a8-986a-44b9-dc73-57f6bd9147ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4000/4000 [==============================] - 79s 19ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(test_ds)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1) +1\n",
        "\n",
        "# Update the 'label' column in the test dataframe with the predicted labels\n",
        "test_df['label'] = predicted_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "UxMW74JyO5i3"
      },
      "outputs": [],
      "source": [
        "selected_columns = ['id', 'label']\n",
        "test_df_selected = test_df[selected_columns]\n",
        "script_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gJBZVta634Gi"
      },
      "outputs": [],
      "source": [
        "test_df_selected = test_df_selected.sort_values(by = 'id')\n",
        "\n",
        "# Generate a timestamp for the filename\n",
        "current_datetime = datetime.datetime.now()\n",
        "timestamp = current_datetime.strftime(\"%Y%m%d_%H%M\")\n",
        "file_name = f\"submission_{timestamp}.csv\"\n",
        "\n",
        "# Define the folder for submissions\n",
        "submissions_folder = os.path.join(script_dir, 'sub')\n",
        "\n",
        "# Specify the full file path\n",
        "file_path = os.path.join(submissions_folder, file_name)\n",
        "\n",
        "# Save the final submission file\n",
        "test_df_selected.to_csv(file_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
